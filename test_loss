import logging
import os.path
from random import uniform
import hydra
from hydra.utils import get_original_cwd
import numpy as np
import torch
from utils.models import FullyConnectedNetwork
import utils.fu as fu
import utils.xiaobo as xiaobo
import matplotlib.pyplot as plt
import utils.equations.Burgers as eq
from utils.pde_utils import fwd_gradients
import pywt  
import utils.xiaobo as xiaobo
import cv2

def xiaobotop(model):
    N = 200
    tspace = np.linspace(0., 0.6, N )
    xspace = np.linspace(-1.,1., N )
    T, X = np.meshgrid(tspace, xspace)
    Xgrid = np.vstack([T.flatten(),X.flatten()]).T
    upred = model(torch.tensor(Xgrid,dtype=torch.float32).cuda())
    U = upred.cpu().detach().numpy().reshape(N,N)
    img = U
    coeffs = pywt.dwt2(img, 'db1')
    p,(q,r,s)=coeffs
    filtered_coeffs_h=(np.zeros_like(p),(q,r,s))
    filtered_img_h = pywt.idwt2(filtered_coeffs_h, 'db1') 
    iimg_h = filtered_img_h.reshape(-1)
    values, indices = torch.topk(torch.tensor(iimg_h), 8000, dim=0,sorted=True)  
    X_h=Xgrid[indices]
    return X_h

def losstop(model):
    def pde_loss(pred, input_tensor):
        df_dt_dx = fwd_gradients(pred, input_tensor)
        df_dt = df_dt_dx[:, 0:1]
        df_dx = df_dt_dx[:, 1:2]
        df_dxx = fwd_gradients(df_dx, input_tensor)[:, 1:2]
        pde_output = df_dt + pred * df_dx - (0.04/torch.pi) * df_dxx
        return pde_output
    def compute_loss_basic_weights(model, data):
        pde_pred = model(data)
        pde_losss = torch.abs(pde_loss(pde_pred, data))
        return pde_losss
    N = 1000
    tspace = np.linspace(0., 0.6, N )
    xspace = np.linspace(-1.,1., N )
    T, X = np.meshgrid(tspace, xspace)
    Xgrid = np.vstack([T.flatten(),X.flatten()]).T
    data=torch.tensor(Xgrid,dtype=torch.float32,requires_grad=True).cuda()
    loss=compute_loss_basic_weights(model=model,data=data)
    '''
    img=loss.cpu().detach().numpy().reshape(N,N)
    coeffs = pywt.dwt2(img, 'db1')
    p,(q,r,s)=coeffs
    filtered_coeffs_h=(np.zeros_like(p),(q,r,s))
    filtered_img_h = pywt.idwt2(filtered_coeffs_h, 'db1') 
    filtered_img_h=(filtered_img_h-np.min(filtered_img_h))/(np.max(filtered_img_h)-np.min(filtered_img_h))*255
    dst = cv2.equalizeHist(filtered_img_h.astype(np.uint8))
    iimg_h = filtered_img_h.reshape(-1)
    '''
    values, indices = torch.topk(torch.tensor(loss.cpu()), 4000, dim=0,sorted=True)  
    X_h=Xgrid[indices]
    return X_h



@hydra.main(version_base=None, config_path="./conf", config_name="evaluation_conf")
def evaluation_setup(cfg):
    model_conf = cfg["model_conf"]
    equation_conf = cfg["equation_conf"]
    device = torch.device("cuda")
    conf=equation_conf['Burgers']
    def pde_loss(pred, input_tensor):
        df_dt_dx = fwd_gradients(pred, input_tensor)
        df_dt = df_dt_dx[:, 0:1]
        df_dx = df_dt_dx[:, 1:2]
        df_dxx = fwd_gradients(df_dx, input_tensor)[:, 1:2]
        pde_output = df_dt + pred * df_dx - (0.04/torch.pi) * df_dxx
        return pde_output
    def compute_loss_basic_weights(model, data):
        pde_pred = model(data)
        pde_losss = torch.abs(pde_loss(pde_pred, data))
        return pde_losss
    #weight_path = "F:/StudyNote/PINN_e/DMIS-main/outputs/2023-11-23/11-48-18/KDV_47000.pth"
    weight_path = "F:/StudyNote/PINN_e/DMIS-main/outputs/2023-12-07/18-57-29/Burgers_18000.pth"
    model_conf["layer"]["layer_n"] = conf["layer_n"]
    model_conf["layer"]["layer_size"] = conf["layer_size"]
    model_conf["dim"]["output_dim"] = conf["output_dim"]
    model = FullyConnectedNetwork(model_conf).to(device)
    model.load_state_dict(torch.load(weight_path))

    N = 1000
    tspace = np.linspace(0., 0.6, N )
    xspace = np.linspace(-1.,1., N )
    T, X = np.meshgrid(tspace, xspace)
    Xgrid = np.vstack([T.flatten(),X.flatten()]).T
    data=torch.tensor(Xgrid,dtype=torch.float32,requires_grad=True).cuda()
    loss=compute_loss_basic_weights(model=model,data=data)
    values, indices = torch.topk(loss, 2000, dim=0,sorted=True)  
    loss_top500=Xgrid[indices.cpu()]
    loss_top500=loss_top500[:,0,:]
    loss_top500[:,0]=loss_top500[:,0]*(1/0.6)
    loss_top500[:,1]=(loss_top500[:,1]+1)*0.5
    '''
    loss_top500=losstop(model)
    loss_top500[:,0]=loss_top500[:,0]*(1/0.6)
    loss_top500[:,1]=(loss_top500[:,1]+1)*0.5
    '''
    xiaobotop500=xiaobotop(model)
    xiaobotop500[:,0]=xiaobotop500[:,0]*(1/0.6)
    xiaobotop500[:,1]=(xiaobotop500[:,1]+1)*0.5
    uniform500[:,0]=uniform500[:,0]*(1/0.6)
    uniform500[:,1]=(uniform500[:,1]+1)*0.5
    for i in [0,10,20,30,40,50]:
        o,uniform500=xiaobo.fusample(model,step=i)
        distances = np.linalg.norm(uniform500[:, np.newaxis] - loss_top500, axis=-1).sum()/(2000*2000)
        print(1-distances)
    #distances = np.linalg.norm(xiaobotop500[:, np.newaxis] - loss_top500, axis=-1).sum()/(4000*4000)
    #distances =np.sum(np.sqrt(np.square(a)[:,0]+np.square(a)[:,1]))
  



    U = loss.cpu().detach().numpy().reshape(N,N)
    fig, (ax1, ax2) = plt.subplots(2, 1)  
    #plt.imshow(U)
    #plt.show()
    ax1.scatter(xiaobotop500[:,0],xiaobotop500[:,1],s=1)
    ax1.set_xlim([0, 1])  
    ax1.set_ylim([0, 1])
    ax2.scatter(loss_top500[:,0],loss_top500[:,1],s=1)
    ax2.set_xlim([0, 1])  
    ax2.set_ylim([0, 1])
    plt.show()

'''
    import matplotlib as mpl
    fig, ax1 = plt.subplots(1, 1)  
    im = ax1.pcolormesh(tspace, xspace, loss.cpu().detach().numpy().reshape(N,N),  shading='auto',norm=mpl.colors.SymLogNorm(linthresh=0.01, linscale=3, vmin=loss.min(), vmax=loss.max(), base=10),cmap='coolwarm')
    cbar = fig.colorbar(im, ax=ax1, orientation='vertical',extend=None,ticks=[1e-6,1e-2])
    print(loss.max(),loss.min())
    plt.show()
'''
evaluation_setup()